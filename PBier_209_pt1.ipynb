{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 209 pt 1\n",
    "##### Question posed:\n",
    "What factors can be used to predict if a patient will be re-admitted within 30 days?\n",
    "- Categorical dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Set up of notebook\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "import plotly.figure_factory as ff\n",
    "# from functions import clean_columns, univariate, winz_outliers # Personal functions\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Import data\n",
    "med_df = pd.read_csv('medical_clean.csv')\n",
    "med_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "## Find duplicates\n",
    "print(med_df.duplicated().value_counts()) # this gives a count of unique values (this case is true/false)\n",
    "print(med_df.duplicated().sum()) # This gives a count of the nymber of duplicates(counting the true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "#Count number of missing values by columns\n",
    "med_df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "## Create Visualizations of the missing value\n",
    "\n",
    "plt.figure(figsize=(12, 8))  # Adjust the figure size as necessary\n",
    "\n",
    "# Create a heatmap to visualize missing data (null values)\n",
    "# Set cbar=False to hide the color bar and add column names (xticklabels) for clarity\n",
    "sns.heatmap(med_df.isnull(), cbar=False, cmap='viridis', yticklabels=False, xticklabels=med_df.columns)\n",
    "plt.xticks(rotation=90)  # Rotate column names for better readability\n",
    "\n",
    "plt.title('Missing Data Visualization')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Rename the data set\n",
    "I do this on all data sets so that I know I have checked for duplicates and NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Rename dataset\n",
    "clean_df = med_df.copy()\n",
    "\n",
    "#Explore the data\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Explore summary statistiscs on a data set\n",
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Clean the data set columns using created function based on tresholds\n",
    "#missing_threshold = 0.95, unique_threshold = 0.95, only 1 value in a column --> removes\n",
    "\n",
    "#Function for cleaning columns\n",
    "def clean_columns(df, columns =[], missing_threshold = 0.95, unique_threshold = 0.95, messages = True):\n",
    "    \n",
    "    if len(columns) == 0:\n",
    "        columns = df.columns #this lets the columns be blank and every columns will be cleaned\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            missing = df[col].isna().sum()\n",
    "            unique = df[col].nunique()\n",
    "            rows = df.shape[0]  \n",
    "            \n",
    "            if missing / rows >= missing_threshold:\n",
    "                if messages: print(f\"To many missing values with ({missing} out of {rows}, {round((missing / rows) * 100, 2)}%) for {col}, removed\")\n",
    "                df.drop(columns =[col], inplace = True)\n",
    "            # For non-numeric columns, check if there are too many unique values\n",
    "            if not pd.api.types.is_numeric_dtype(df[col]) and (unique / rows >= unique_threshold):\n",
    "                if messages: \n",
    "                    print(f\"Too many unique values with ({unique} out of {rows}, {round((unique / rows) * 100, 2)}%) for {col}, removed\")\n",
    "                df.drop(columns=[col], inplace=True)\n",
    "                continue\n",
    "            elif unique == 1:\n",
    "                if messages: print(f\"Only one value in ({df[col].unique()[0]} for {col}, removed\")\n",
    "                df.drop(columns =[col], inplace = True)\n",
    "         \n",
    "        else:\n",
    "            if messages: print(f\"The column variable \\\"{col}\\\" doesnt exist as spelled in the DataFrame provided\")\n",
    "     \n",
    "    return df\n",
    "\n",
    "clean_columns(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Verify / Re-examine\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Remove the index column\n",
    "clean_df = clean_df.iloc[:, 1:]\n",
    "#Verify\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def univariate(df, plot=False):\n",
    "    stats = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_data = df[col].dropna()  # Drop NA early to avoid repeated calculation\n",
    "        dtype = col_data.dtype\n",
    "        desc = col_data.describe() if pd.api.types.is_numeric_dtype(col_data) else None\n",
    "        \n",
    "        stats_row = {\n",
    "            \"Variable\": col,\n",
    "            \"Type\": dtype,\n",
    "            \"Count\": desc['count'] if desc is not None else col_data.count(),\n",
    "            \"Missing\": df[col].isna().sum(),\n",
    "            \"Unique\": col_data.nunique(),\n",
    "            \"Mode\": col_data.mode().iloc[0] if not col_data.mode().empty else None\n",
    "        }\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            stats_row.update({\n",
    "                \"Min\": desc['min'],\n",
    "                \"Q1\": desc['25%'],\n",
    "                \"Median\": desc['50%'],\n",
    "                \"Q3\": desc['75%'],\n",
    "                \"Max\": desc['max'],\n",
    "                \"Mean\": desc['mean'],\n",
    "                \"Std\": desc['std'],\n",
    "                \"Skew\": col_data.skew(),\n",
    "                \"Kurt\": col_data.kurt()\n",
    "            })\n",
    "            if plot:\n",
    "                sns.histplot(col_data, kde=True)\n",
    "                plt.title(f'Histogram of {col}')\n",
    "                plt.show()\n",
    "        else:\n",
    "            stats_row.update({\"Min\": \"-\", \"Q1\": \"-\", \"Median\": \"-\", \"Q3\": \"-\", \"Max\": \"-\", \"Mean\": \"-\", \"Std\": \"-\", \"Skew\": \"-\", \"Kurt\": \"-\"})\n",
    "            if plot:\n",
    "                sns.countplot(x=col_data, data=df)\n",
    "                plt.title(f'Count Plot of {col}')\n",
    "                plt.show()\n",
    "\n",
    "        stats.append(stats_row)\n",
    "\n",
    "    output_df = pd.DataFrame(stats)\n",
    "    output_df.set_index(\"Variable\", inplace=True)\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "univariate(clean_df, plot = True) # takes a lot of memory for all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "## Choose variables to narrow down\n",
    "# ReAdmis, TotalCharge, Population, Children, Age, Income, VitD_levels, Doc_visits, Full_meals_eaten, vitD_supp, Initial_days, Additional_charges, Gender, Initial_admin, Complication_risk, HighBlood, Diabetes, Hyperlipidemia, Services\n",
    "\n",
    "knn_data = clean_df[[\n",
    "    \"ReAdmis\", \"TotalCharge\", \"Population\", \"Children\", \"Age\", \"Income\",\n",
    "    \"VitD_levels\", \"Doc_visits\", \"Full_meals_eaten\", \"vitD_supp\",\n",
    "    \"Initial_days\", \"Additional_charges\", \"Gender\", \"Initial_admin\",\n",
    "    \"Complication_risk\", \"HighBlood\", \"Diabetes\", \"Hyperlipidemia\", \"Services\"\n",
    "]].copy()\n",
    "#Verify new data set\n",
    "knn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "## Remove spaces in catagory names within columns\n",
    "# To replace spaces with underscores in specific columns\n",
    "\n",
    "for col in knn_data.columns:\n",
    "     if not pd.api.types.is_numeric_dtype(knn_data[col]):\n",
    "        knn_data[col] = knn_data[col].str.replace(\" \", \"_\", regex = False) \n",
    "        \n",
    "##Clean White Space and make all lower case\n",
    "knn_data.columns = knn_data.columns.str.lower().str.strip()       \n",
    "\n",
    "#round values to 2 decimal points\n",
    "knn_data = knn_data.round(2)\n",
    "\n",
    "#Verify space removal/ replacement\n",
    "knn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "## Detect and clean outliers\n",
    "\n",
    "##Function for Winsorization of outliers, using IQR\n",
    "#https://towardsdatascience.com/detecting-and-treating-outliers-in-python-part-3-dcb54abaf7b0\n",
    "def winz_outliers(df):\n",
    "    \n",
    "    print(\"Outlier Analysis Report\")\n",
    "    print(\"=\" * 50)  # Print a separator line for visual clarity\n",
    "    \n",
    "    for col in df:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]): \n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR)))\n",
    "            outlier_count = outliers.sum()\n",
    "            \n",
    "            if outlier_count > 0:\n",
    "                outer_fence = 3 * IQR\n",
    "                outer_fence_low = Q1 - outer_fence\n",
    "                outer_fence_up = Q3 + outer_fence\n",
    "                \n",
    "                # Consolidating the print statements for each column\n",
    "                print(f\"\\nColumn: {col}\")\n",
    "                print(f\"Number of Outliers: {outlier_count}\")\n",
    "                print(f\"Lower Outer Fence: {round(outer_fence_low, 2)}\")\n",
    "                print(f\"Upper Outer Fence: {round(outer_fence_up, 2)}\")\n",
    "\n",
    "    print(\"=\" * 50)  # End with a separator line for visual clarity\n",
    "\n",
    "\n",
    "winz_outliers(knn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Create a boxplot for each column with outliers\n",
    "outlier_shape = knn_data[[\"population\", \"children\",\"income\", \"vitd_levels\", \"full_meals_eaten\", \"vitd_supp\", \"additional_charges\"]]\n",
    "\n",
    "for column in outlier_shape:\n",
    "    sns.boxenplot(x=knn_data[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "##choose variable to treat outliers\n",
    "## Winzorize the outliers\n",
    "#from scipy.stats.mstats import winsorize\n",
    "import warnings\n",
    "## I am Sure that there are no NaN or partition errors\n",
    "warnings.filterwarnings('ignore', message=\"Warning: 'partition' will ignore the 'mask' of the MaskedArray\")\n",
    "\n",
    "#Choose variables to winsorize - Population, income, VitD_levels, Full_meals_eaten\n",
    "#Note that VitD levels will also need a lower limit calculation\n",
    "#When using the limits, you are specifying \"how much\" to take off, not the \"where\" to take off\n",
    "\n",
    "knn_data['population_winz'] = winsorize(knn_data['population'], limits=(0, 0.05))\n",
    "knn_data['income_winz'] = winsorize(knn_data['income'], limits=(0, 0.05))\n",
    "knn_data['vitd_levels_winz'] = winsorize(knn_data['vitd_levels'], limits=(0.05, 0.01))\n",
    "knn_data['full_meals_winz'] = winsorize(knn_data['full_meals_eaten'], limits=(0, 0.05))\n",
    "\n",
    "univariate(knn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Verify\n",
    "print(knn_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Remake data set with the outliers removed\n",
    "knn_data = knn_data.drop(columns=[\"population\", \"income\", \"vitd_levels\", \"full_meals_eaten\"], axis = 1)\n",
    "\n",
    "#verify removal\n",
    "print(knn_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "## Function for changing binary values to 0/1 \n",
    "#AND creating dummy var WITH ALL VARIABLES KEPT\n",
    "\n",
    "def wrangle_cat(df):\n",
    "    #handle binary categorical variables\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_string_dtype(df[col]):\n",
    "            # standardize the text format to lowercase\n",
    "            df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "            # find binary columns with yes/ no or true/false\n",
    "            if df[col].isin(['yes', 'no', 'true', 'false']).all():\n",
    "                mapping = {'yes': 1, 'no': 0, 'true': 1, 'false': 0}\n",
    "                df[col] = df[col].map(mapping)\n",
    "    \n",
    "    # one-hot encode the remaining categorical variables\n",
    "    # Ensure to only encode those that haven't been converted to numeric in the previous step\n",
    "    categorical_cols = df.columns[df.dtypes == 'object']\n",
    "    df = pd.get_dummies(df, columns = categorical_cols, dtype = int, drop_first = False)\n",
    "                \n",
    "    return df\n",
    "\n",
    "\n",
    "knn_encoded = wrangle_cat(knn_data)\n",
    "print(knn_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Verify encoding\n",
    "knn_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "#Lasso for feature selection\n",
    "\n",
    "X = knn_encoded.drop([\"readmis\"], axis = 1)\n",
    "y = knn_encoded[\"readmis\"]\n",
    "\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso_coef = np.abs(lasso.fit(X, y).coef_)\n",
    "\n",
    "# Use the columns from X for names\n",
    "lasso_names = X.columns\n",
    "\n",
    "# Plot\n",
    "# https://medium.com/@agrawalsam1997/feature-selection-using-lasso-regression-10f49c973f08\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Optional: Adjusts the figure size for better readability\n",
    "plt.bar(lasso_names, lasso_coef)\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()\n",
    "plt.title(\"Feature Selection Based on Lasso\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Feature selection\n",
    "#Select score_function basedon type of model build wanted.\n",
    "#https://medium.com/@Kavya2099/optimizing-performance-selectkbest-for-efficient-feature-selection-in-machine-learning-3b635905ed48\n",
    "\n",
    "skbest = SelectKBest(score_func = f_classif, k ='all')  # Adjust 'k' based on feature selection strategy\n",
    "X_new = skbest.fit_transform(X, y)\n",
    "X_new.shape\n",
    "\n",
    "p_values = pd.DataFrame({\"Feature\": X.columns, \"p_value\":skbest.pvalues_}).sort_values(\"p_value\")\n",
    "p_values[p_values[\"p_value\"] < .05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Going to use features from both these models to create the variables for the knn\n",
    "# \"readmis\", \"totalcharge\", \"initial_days\", \"children\", \"initial_admin_emergency_admission\"\n",
    "\n",
    "knn_features = knn_encoded[[\"readmis\", \"totalcharge\", \"initial_days\",\"services_ct_scan\", \"services_intravenous\", \"children\", \"initial_admin_emergency_admission\"]].copy()\n",
    "knn_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# DataFrame of knn_encoded has been cleaned and is ready for use in the analysis model.\n",
    "# Export the data set as csv\n",
    "\n",
    "# Download clean data as csv\n",
    "knn_features.to_csv('KNN_features_209.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Split the Data\n",
    "# will split to 80% train, 20% test\n",
    "# Data will be statitified to ensure accurate proportions of samples from catagories\n",
    "\n",
    "X = knn_features.drop([\"readmis\"], axis=1)\n",
    "y = knn_features[\"readmis\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y,\n",
    "    test_size=0.2,  # Specifies 20% of the data for testing\n",
    "    random_state=42,  # Ensures reproducibility\n",
    "    stratify=y  # Stratifies the split based on the labels in 'y'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Standardize the values using scale\n",
    "scale = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scale.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scale.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Concatenate scaled features with the target variable\n",
    "train_data = pd.concat([X_train_scaled, y_train.reset_index(drop=True)], axis=1)\n",
    "test_data = pd.concat([X_test_scaled, y_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the head of the training data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Export testing and training files\n",
    "\n",
    "X_train_scaled.to_csv(\"Xscale_train_209.csv\", index=False)\n",
    "X_test_scaled.to_csv(\"Xscale_test_209.csv\", index = False)\n",
    "y_train.to_csv(\"Y_train_209.csv\", index = False)\n",
    "y_test.to_csv(\"Y_test_209.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Initialize and train the KNN classifier on the training data\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on both the training and test datasets\n",
    "train_accuracy = knn.score(X_train_scaled, y_train)\n",
    "test_accuracy = knn.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Training Accuracy: {train_accuracy}')\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "##run hyperparameter testing\n",
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "neighbors = np.arange(1, 20)\n",
    "\n",
    "for neighbor in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_accuracies[neighbor] = knn.score(X_train_scaled, y_train)\n",
    "    test_accuracies[neighbor] = knn.score(X_test_scaled, y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(\"KNN: Varying Number of Neighbors\")\n",
    "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
    "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Find the key (neighbor value) with the highest test accuracy\n",
    "best_k = max(test_accuracies, key=test_accuracies.get)\n",
    "best_test_accuracy = test_accuracies[best_k]\n",
    "best_train_accuracy = train_accuracies[best_k]\n",
    "\n",
    "print(f\"The best value of k is {best_k}, with a test accuracy of {best_test_accuracy:.2f} and a training accuracy of {best_train_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Hyperparameter tuning with GridsearchCV \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Hyperparameter testing\n",
    "\n",
    "kf = KFold(n_splits = 5,shuffle = True,random_state = 42)\n",
    "parameter = {'n_neighbors': np.arange(1, 20, 1)}\n",
    "knn_best = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn_best, param_grid = parameter, cv=kf, scoring = \"accuracy\", verbose = 1)\n",
    "knn_cv.fit(X_train_scaled, y_train)\n",
    "print(knn_cv.best_params_)\n",
    "print(knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Final Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Re-run KNN with the best found k value on training data only\n",
    "knn_best = KNeighborsClassifier(n_neighbors= 7)\n",
    "knn_best.fit(X_train_scaled, y_train)\n",
    "y_pred = knn_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model again on both the training and test datasets with the best k\n",
    "train_accuracy_best = knn_best.score(X_train_scaled, y_train)\n",
    "test_accuracy_best = knn_best.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Best K Training Accuracy: {train_accuracy_best}')\n",
    "print(f'Best K Test Accuracy: {test_accuracy_best}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Determine model accuracy\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Creating a DataFrame from the confusion matrix with labels\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, \n",
    "                              index=['Actual Negative', 'Actual Positive'], \n",
    "                              columns=['Predicted Negative', 'Predicted Positive'])\n",
    "\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Normalize by the number of instances in each actual class\n",
    "conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(conf_matrix_norm, annot=True, fmt='.2f', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Interactive confusion matrix\n",
    "\n",
    "z = conf_matrix\n",
    "x = ['Predicted No', 'Predicted Yes']\n",
    "y = ['Actual No', 'Actual Yes']\n",
    "\n",
    "fig = ff.create_annotated_heatmap(z, x=x, y=y, colorscale='Blues')\n",
    "fig.update_layout(title='Interactive Confusion Matrix', xaxis=dict(title='Predicted Label'), yaxis=dict(title='Actual Label'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Sensitivity and specificity\n",
    "\n",
    "#             Predicted No     Predicted Yes\n",
    "# Actual No    TN               FP\n",
    "# Actual Yes   FN               TP\n",
    "\n",
    "# Precision for the positive class '1'\n",
    "# precision = TP / (TP + FP)\n",
    "\n",
    "TP = conf_matrix[1, 1] #True Positives\n",
    "TN = conf_matrix[0, 0] #True Negatives\n",
    "FP = conf_matrix[0, 1] #False Positives\n",
    "FN = conf_matrix[1, 0] #False Negatives\n",
    "\n",
    "total = (TP + TN + FP + FN)\n",
    "\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "accuracy = (TN + TP) / total\n",
    "# Precision for the positive class '1'\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "print(\"Sensitivity (True Positive Rate or Recall):\", sensitivity.round(2))\n",
    "print(\"Specificity (True Negative Rate):\", specificity. round(2))\n",
    "print(\"Accuracy: \", accuracy.round(2))\n",
    "print(\"Precision for 'Yes' : \", precision.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "## ROC and AUC\n",
    "# Generate probability scores \n",
    "y_pred_prob = knn.predict_proba(X_test_scaled)[ :, 1]\n",
    "\n",
    "# Calculate ROC curve\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate AUC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(false_positive_rate, true_positive_rate, color='darkorange', lw=2, label=f'ROC curve (area = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}